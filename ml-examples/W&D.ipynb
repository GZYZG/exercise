{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15664c1-7fb2-4995-8c8b-e76b434e932e",
   "metadata": {},
   "source": [
    "# Wide&Deep\n",
    "\n",
    "Wide&Deep 是 Google 在 2016 年发表于 DLRS 上的论文中提出来的，结合了 Wide 模型的 `Memorization` 和 Deep 模型的 `Generalization`。一句话介绍：  \n",
    "**W&D由浅层（或单层）的Wide部分神经网络和深层的Deep部分多层神经网络组成，输出层采用softmax或logistics regression综合Wide和Deep部分的输出。**\n",
    "\n",
    "![Wide & Deep](imgs/W&D.jpg)\n",
    "\n",
    "如上图所示，W&D 由两部分组成：Wide 和 Deep。Wide 是一个广义的线性模型，用于捕捉在历史数据中出现过的模式 / 特征规律。Deep 是一个前馈神经网络，通过稀疏的类别特征学习特征稠密、低低维的 embedding，有更好的泛化性能。\n",
    "\n",
    "Wide 是一个广义的线性模型，一般是逻辑回归模型：\n",
    "$$\n",
    "y_{wide} = \\boldsymbol{w}^T \\boldsymbol{x} + b,\\ \\boldsymbol{x} \\in \\mathbb{R}^d\n",
    "$$\n",
    "并且 Wide 部分可以加入人工构造的特征，即人工设计交叉特征，如交叉特征 $\\phi_k$:\n",
    "$$\n",
    "\\phi_K(\\boldsymbol{x}) = \\prod_{i=1}^d x_i^{c_{ki}}\n",
    "$$\n",
    "其中 $c_{ki}$ 表示第 $i$ 个特征 $x_i$ 是否出现在交叉特征 $\\phi_k$ 中。\n",
    "\n",
    "Deep 是一个前馈神经网络，一般是由多层神经网络组成。\n",
    "$$\n",
    "y_{deep} = DNN(\\boldsymbol{x})\n",
    "$$\n",
    "\n",
    "最终二者相加后经过 `sigmoid` 激活函数得到最终的输出：\n",
    "$$\n",
    "P(Y = 1 | \\boldsymbol{x}) = \\hat{y} = \\sigma(\\boldsymbol{w}_{wide}^T [\\boldsymbol{x}, \\phi(\\boldsymbol{x})] + \\boldsymbol{w}^T_{deep} \\boldsymbol{a}^{l_f} + b)\n",
    "$$\n",
    "\n",
    "其实从这个式子我们也可以看出，Wide&Deep 将输入 sigmoid 之前的回归值拆成了两部分，一部分来自 Wide 部分，一部分来自 Deep 部分。Wide 和 Deep 是联合训练的，通过梯度下降来更新参数，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d414aa-be9e-45bc-8ee2-a668487b01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import  MinMaxScaler, LabelEncoder\n",
    "\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c450b9f2-30b8-429b-a0e3-e7d7cf310f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/criteo_sample.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf0f9307-a45e-4006-9bb9-f1c263eb6d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>260.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17668.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>87c6f83c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0429f84b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>c0d61a5c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30251.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d4bb7bd8</td>\n",
       "      <td>6fc84bfb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5155d8a3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>be7c41b4</td>\n",
       "      <td>ded4aac9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>675c9258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2e01979f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>6d5d1302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16836.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>52e44668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e587c466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>3b183c5c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>25c88e42</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>0e8585d2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>0d4a6d1a</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>92c878de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3036.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>9880032b</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>34cc61bb</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>e5ed7da2</td>\n",
       "      <td>ea9a246c</td>\n",
       "      <td>984e0db0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>3972b4ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d1aa4512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>9257f75f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3486227d</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>54591762</td>\n",
       "      <td>a458ea53</td>\n",
       "      <td>4a2c3526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>1a02cbe1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3486227d</td>\n",
       "      <td>13145934</td>\n",
       "      <td>55dd3565</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>bf647035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>1481ceb4</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>988b0775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d4bb7bd8</td>\n",
       "      <td>908eaeb8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label   I1  I2     I3    I4       I5     I6    I7    I8     I9  ...  \\\n",
       "0        0  NaN   3  260.0   NaN  17668.0    NaN   NaN  33.0    NaN  ...   \n",
       "1        0  NaN  -1   19.0  35.0  30251.0  247.0   1.0  35.0  160.0  ...   \n",
       "2        0  0.0   0    2.0  12.0   2013.0  164.0   6.0  35.0  523.0  ...   \n",
       "3        0  NaN  13    1.0   4.0  16836.0  200.0   5.0   4.0   29.0  ...   \n",
       "4        0  0.0   0  104.0  27.0   1990.0  142.0   4.0  32.0   37.0  ...   \n",
       "..     ...  ...  ..    ...   ...      ...    ...   ...   ...    ...  ...   \n",
       "195      0  NaN   0  113.0   3.0   3036.0  575.0   2.0   3.0  214.0  ...   \n",
       "196      1  0.0   1    1.0   1.0   1607.0   12.0   1.0  12.0   15.0  ...   \n",
       "197      1  1.0   0    6.0   3.0      0.0    0.0  19.0   3.0    3.0  ...   \n",
       "198      0  0.0  22    6.0  22.0    203.0  153.0  80.0  18.0  508.0  ...   \n",
       "199      0  1.0  -1    NaN   NaN    138.0    0.0   1.0   0.0    0.0  ...   \n",
       "\n",
       "          C17       C18       C19       C20       C21       C22       C23  \\\n",
       "0    e5ba7672  87c6f83c       NaN       NaN  0429f84b       NaN  3a171ecb   \n",
       "1    d4bb7bd8  6fc84bfb       NaN       NaN  5155d8a3       NaN  be7c41b4   \n",
       "2    e5ba7672  675c9258       NaN       NaN  2e01979f       NaN  bcdee96c   \n",
       "3    e5ba7672  52e44668       NaN       NaN  e587c466       NaN  32c7478e   \n",
       "4    e5ba7672  25c88e42  21ddcdc9  b1252a9d  0e8585d2       NaN  32c7478e   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "195  07c540c4  9880032b  21ddcdc9  5840adea  34cc61bb  c9d4222a  32c7478e   \n",
       "196  1e88c74f  3972b4ed       NaN       NaN  d1aa4512       NaN  32c7478e   \n",
       "197  3486227d  5aed7436  54591762  a458ea53  4a2c3526       NaN  32c7478e   \n",
       "198  3486227d  13145934  55dd3565  5840adea  bf647035       NaN  32c7478e   \n",
       "199  d4bb7bd8  908eaeb8       NaN       NaN       NaN       NaN  32c7478e   \n",
       "\n",
       "          C24       C25       C26  \n",
       "0    c0d61a5c       NaN       NaN  \n",
       "1    ded4aac9       NaN       NaN  \n",
       "2    6d5d1302       NaN       NaN  \n",
       "3    3b183c5c       NaN       NaN  \n",
       "4    0d4a6d1a  001f3601  92c878de  \n",
       "..        ...       ...       ...  \n",
       "195  e5ed7da2  ea9a246c  984e0db0  \n",
       "196  9257f75f       NaN       NaN  \n",
       "197  1793a828  e8b83407  1a02cbe1  \n",
       "198  1481ceb4  e8b83407  988b0775  \n",
       "199       NaN       NaN       NaN  \n",
       "\n",
       "[200 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(data_path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef05fc32-85fd-4299-851f-0e9d6ff98b63",
   "metadata": {},
   "source": [
    "# tensorflow 实现\n",
    "\n",
    "参见：[WideNDeep-tf.py](./WideNDeep-tf.py)。该实现来自[这里](https://github.com/datawhalechina/fun-rec/blob/master/codes/base_models/WideNDeep.py)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdecf4b-c418-4ae9-add0-45eeb83945b3",
   "metadata": {},
   "source": [
    "# pytorch 实现\n",
    "\n",
    "参见：[Wide-and-Deep-PyTorch](https://github.com/zenwan/Wide-and-Deep-PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7dc052a-de4e-4e29-8c00-b7e167672de7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 30, Loss: 0.124, accuracy: 0.8114, auc: 0.8254855874544342\n",
      "Epoch 2 of 30, Loss: 0.096, accuracy: 0.8355, auc: 0.8801040007735794\n",
      "Epoch 3 of 30, Loss: 0.257, accuracy: 0.8386, auc: 0.8864987525289237\n",
      "Epoch 4 of 30, Loss: 0.318, accuracy: 0.839, auc: 0.8896156035948188\n",
      "Epoch 5 of 30, Loss: 0.531, accuracy: 0.8406, auc: 0.8920132984630393\n",
      "Epoch 6 of 30, Loss: 0.348, accuracy: 0.844, auc: 0.8930158009125934\n",
      "Epoch 7 of 30, Loss: 0.445, accuracy: 0.8466, auc: 0.8943107536601095\n",
      "Epoch 8 of 30, Loss: 0.249, accuracy: 0.8442, auc: 0.8956991576959826\n",
      "Epoch 9 of 30, Loss: 0.338, accuracy: 0.8458, auc: 0.8973800437512327\n",
      "Epoch 10 of 30, Loss: 0.41, accuracy: 0.8467, auc: 0.8987414740106183\n",
      "Epoch 11 of 30, Loss: 0.603, accuracy: 0.8478, auc: 0.8983957581701015\n",
      "Epoch 12 of 30, Loss: 0.137, accuracy: 0.8484, auc: 0.8991320650794434\n",
      "Epoch 13 of 30, Loss: 0.274, accuracy: 0.8492, auc: 0.8999786779222705\n",
      "Epoch 14 of 30, Loss: 0.054, accuracy: 0.8472, auc: 0.9006401170054964\n",
      "Epoch 15 of 30, Loss: 0.262, accuracy: 0.8474, auc: 0.900556092264273\n",
      "Epoch 16 of 30, Loss: 0.727, accuracy: 0.8498, auc: 0.9018079250351063\n",
      "Epoch 17 of 30, Loss: 0.109, accuracy: 0.8492, auc: 0.9017942689659829\n",
      "Epoch 18 of 30, Loss: 0.16, accuracy: 0.8488, auc: 0.9029672845945423\n",
      "Epoch 19 of 30, Loss: 0.426, accuracy: 0.8496, auc: 0.9026081981776363\n",
      "Epoch 20 of 30, Loss: 0.179, accuracy: 0.8499, auc: 0.9038383863696886\n",
      "Epoch 21 of 30, Loss: 0.256, accuracy: 0.8512, auc: 0.9039053925718068\n",
      "Epoch 22 of 30, Loss: 0.192, accuracy: 0.8512, auc: 0.9042476349173896\n",
      "Epoch 23 of 30, Loss: 0.125, accuracy: 0.852, auc: 0.9041477441818035\n",
      "Epoch 24 of 30, Loss: 0.254, accuracy: 0.8533, auc: 0.9054861552677611\n",
      "Epoch 25 of 30, Loss: 0.475, accuracy: 0.8518, auc: 0.9057271692914289\n",
      "Epoch 26 of 30, Loss: 0.279, accuracy: 0.8521, auc: 0.9055680282396724\n",
      "Epoch 27 of 30, Loss: 0.189, accuracy: 0.8529, auc: 0.9072347031010379\n",
      "Epoch 28 of 30, Loss: 0.448, accuracy: 0.8545, auc: 0.9076794743465482\n",
      "Epoch 29 of 30, Loss: 0.348, accuracy: 0.8519, auc: 0.9067043739125832\n",
      "Epoch 30 of 30, Loss: 0.292, accuracy: 0.8534, auc: 0.9076442477152784\n",
      "0.8363189681646023\n",
      "[[9.98262823e-01 1.73714769e-03]\n",
      " [9.92567003e-01 7.43299397e-03]\n",
      " [7.65521049e-01 2.34478965e-01]\n",
      " [9.99983907e-01 1.60889613e-05]\n",
      " [9.98684347e-01 1.31566089e-03]\n",
      " [3.82983685e-01 6.17016315e-01]\n",
      " [9.14116442e-01 8.58835429e-02]\n",
      " [6.96324110e-01 3.03675860e-01]\n",
      " [9.77747560e-01 2.22524554e-02]\n",
      " [9.97996449e-01 2.00355938e-03]]\n",
      "{' 10th': array([ 0.82826495, -2.3491192 ,  0.7309242 , -1.2102922 ,  0.9613809 ,\n",
      "        0.03941771,  0.34563318,  0.16262467,  0.31079653, -0.27248132],\n",
      "      dtype=float32), ' 11th': array([ 0.6394022 ,  0.86996174,  1.452726  , -0.53243655,  0.49405363,\n",
      "       -0.08507566, -1.1522892 , -0.64294976, -0.04132851,  1.4973106 ],\n",
      "      dtype=float32), ' 12th': array([-1.2217124 , -0.36613783, -0.3191295 , -0.75849044,  0.11530706,\n",
      "       -0.98363   , -2.0576022 , -1.8433264 , -0.88894486,  1.1029984 ],\n",
      "      dtype=float32), ' 1st-4th': array([-0.72289246,  0.45774513,  0.30925977, -1.1086938 , -0.7211325 ,\n",
      "       -0.43790692,  0.4350044 , -2.5905662 , -1.6149647 ,  0.8691106 ],\n",
      "      dtype=float32), ' 5th-6th': array([-4.4553575e-01, -7.5114012e-02,  9.0994767e-04, -1.2148048e+00,\n",
      "        1.6589297e-02, -8.6166406e-01, -1.5606383e+00,  2.1105322e-01,\n",
      "       -4.5257178e-01,  6.6951883e-01], dtype=float32), ' 7th-8th': array([ 1.4845878 , -0.04726894, -0.15754022, -0.73065794, -0.23174237,\n",
      "        1.0061382 , -2.118001  ,  1.4961492 ,  0.5453827 , -1.949535  ],\n",
      "      dtype=float32), ' 9th': array([-0.73885053, -1.949956  ,  1.6863264 , -0.33709866,  0.829468  ,\n",
      "       -0.27494943, -0.17934354,  0.9956832 , -0.16695283, -1.3543983 ],\n",
      "      dtype=float32), ' Assoc-acdm': array([ 0.00756259,  0.66123575, -0.3642889 , -0.62036   , -0.22163272,\n",
      "       -0.5197002 ,  1.4304786 ,  0.510404  , -0.29278255, -1.1428016 ],\n",
      "      dtype=float32), ' Assoc-voc': array([-0.7541726 , -0.79935676,  0.8080551 ,  0.26670268,  0.05982909,\n",
      "        1.2369028 , -0.5181448 , -0.03054187,  0.9963859 ,  1.2787368 ],\n",
      "      dtype=float32), ' Bachelors': array([ 0.77364165,  0.02745125,  0.7716403 , -0.53296596, -1.1033759 ,\n",
      "       -1.520064  , -0.34173766, -0.880026  , -0.10020511, -1.2944889 ],\n",
      "      dtype=float32), ' Doctorate': array([ 0.14975926,  0.38159934, -1.0125436 ,  0.8433429 ,  0.21092136,\n",
      "       -1.642632  ,  1.1920681 , -0.8848174 ,  0.27392274, -0.04531393],\n",
      "      dtype=float32), ' HS-grad': array([-0.16204868,  1.2000202 , -0.1061864 , -0.42479697,  1.1227976 ,\n",
      "        0.51873344,  0.11832295,  0.6343006 , -1.0816976 ,  0.3985333 ],\n",
      "      dtype=float32), ' Masters': array([-1.1011454 , -1.2692144 , -0.23004527, -0.17225273, -0.6642602 ,\n",
      "        1.4114922 , -0.03885695, -0.00453596,  1.5370531 , -1.2917136 ],\n",
      "      dtype=float32), ' Preschool': array([-1.6315867 ,  0.7489338 ,  1.9056382 , -1.3894036 ,  1.6918849 ,\n",
      "        0.25738734, -0.0511388 , -1.994192  , -1.5890185 ,  2.5220654 ],\n",
      "      dtype=float32), ' Prof-school': array([-1.2022024 , -0.37364846, -0.54215974,  1.3462019 , -0.4648112 ,\n",
      "       -0.40245524, -0.4453055 ,  1.3165733 ,  0.26709506,  1.7560793 ],\n",
      "      dtype=float32), ' Some-college': array([ 2.0487492 , -0.7386682 ,  1.4409934 ,  1.3425566 ,  0.4893025 ,\n",
      "        1.3402412 ,  0.49667862, -1.2493982 , -0.4894534 ,  0.13525791],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from WideNDeep_pt import WideDeep\n",
    "from data_utils import prepare_data\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    DF = pd.read_csv('data/adult.csv')\n",
    "    DF['income_label'] = (DF[\"income\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "\n",
    "    # Experiment set up\n",
    "    ## 定义 wide 部分使用的特征，一般是类别特征；定义交叉特征，一般是二元类别特征的交叉；定义 deep 部分需要 embedding 的特征，一般是类别特征；定义 deep 部分的连续值特征，一般是实数型特征。\n",
    "    wide_cols = ['age','hours_per_week','education', 'relationship','workclass',\n",
    "                 'occupation','native_country','gender']\n",
    "    crossed_cols = (['education', 'occupation'], ['native_country', 'occupation'])\n",
    "    embeddings_cols = [('education',10), ('relationship',8), ('workclass',10),\n",
    "                        ('occupation',10),('native_country',10)]\n",
    "    continuous_cols = [\"age\",\"hours_per_week\"]\n",
    "    target = 'income_label'\n",
    "    method = 'logistic'\n",
    "\n",
    "    # Prepare data\n",
    "    wd_dataset = prepare_data(\n",
    "        DF, wide_cols,\n",
    "        crossed_cols,\n",
    "        embeddings_cols,\n",
    "        continuous_cols,\n",
    "        target,\n",
    "        scale=True)\n",
    "\n",
    "    # Network set up\n",
    "    wide_dim = wd_dataset['train_dataset'].wide.shape[1]\n",
    "    n_unique = len(np.unique(wd_dataset['train_dataset'].labels))\n",
    "    if (method==\"regression\") or (method==\"logistic\"):\n",
    "        n_class = 1\n",
    "    else:\n",
    "        n_class = n_unique\n",
    "    deep_column_idx = wd_dataset['deep_column_idx']  # dict, 类别特征 => 在 deep 数据中的索引\n",
    "    embeddings_input= wd_dataset['embeddings_input']  # list, 每个元素为：(类别特征名字, 类别特征取值数, 类别特征表征长度)\n",
    "    encoding_dict   = wd_dataset['encoding_dict']  # dict, 类别特征 => {取值 => idx}\n",
    "    hidden_layers = [256, 128, 64]\n",
    "    dropout = [0.5, 0.2, .2]\n",
    "\n",
    "    model = WideDeep(\n",
    "        wide_dim,\n",
    "        embeddings_input,\n",
    "        continuous_cols,\n",
    "        deep_column_idx,\n",
    "        hidden_layers,\n",
    "        dropout,\n",
    "        encoding_dict,\n",
    "        n_class)\n",
    "    model.compile(method=method)\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    train_dataset = wd_dataset['train_dataset']\n",
    "    model.fit(dataset=train_dataset, n_epochs=30, batch_size=128)\n",
    "\n",
    "    test_dataset  = wd_dataset['test_dataset']\n",
    "    print((model.predict(dataset=test_dataset)==test_dataset.labels).sum() / len(test_dataset.labels))\n",
    "    print(model.predict_proba(dataset=test_dataset)[:10])\n",
    "    print(model.get_embeddings('education'))\n",
    "\n",
    "    # save\n",
    "#     MODEL_DIR = 'model'\n",
    "#     if not os.path.exists(MODEL_DIR):\n",
    "#         os.makedirs(MODEL_DIR)\n",
    "#     torch.save(model.state_dict(), os.path.join(MODEL_DIR,'logistic.pkl'))\n",
    "\n",
    "    # load model\n",
    "    # model = WideDeep(\n",
    "    #     wide_dim,\n",
    "    #     embeddings_input,\n",
    "    #     continuous_cols,\n",
    "    #     deep_column_idx,\n",
    "    #     hidden_layers,\n",
    "    #     dropout,\n",
    "    #     encoding_dict,\n",
    "    #     n_class)\n",
    "    # model.compile(method=method)\n",
    "    # model.load_state_dict(torch.load('model/logistic.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47a1d6e-ab5d-44c6-9e2d-a327ff1b32e5",
   "metadata": {},
   "source": [
    "# 总结\n",
    "**一些问题：**\n",
    "1. 为什么 Wide 侧会有记忆性？  \n",
    "因为 Wide 侧的输入来源于类别特征，通常会对类别特征进行 one-hot 展开，而 Wide 侧是一个线性模型，会对不同特征有不同的权重，权重的大小反映了特征的强弱。在历史数据中出现过的一些特征组合会体现在权重的大小上，当再次出现类似的特征时，强的特征（组合）会获得更高的预测值，这就是 Wide 侧的记忆能力。Wide 部分学习的是历史数据中特征的共现频率，**如果一个特征组合于目标变量有很强的正相关，则该特征组合会获得较高的权重**。\n",
    "\n",
    "2. 对于输入给 Wide 侧的数值特征，还会有记忆能力吗？  \n",
    "xxx\n",
    "\n",
    "3. 为什么推荐算法的网络层数都不高?   \n",
    "网络层数太深会导致模型难以训练，误差反向传播过程中，越底层的网络训练难度越大。庞大的embedding层可能更加难以训练(好像有看到说对于embedding可能会采用不同的学习率，对于频繁更新的，学习率较小，而更新不频繁的，学习率较大）。推荐系统的网络并不是做不深，而是不能太深。原因有二，1) 深度的网络需要大量的信息来进行拟合的，而推荐系统的输入往往是一些高维度的稀疏特征，携带的信息有限，因此只需要较浅的网络就足够学习了，如果强行增加深度，反而网络不能收敛；2) 推荐系统往往是一个实时打分的系统，个人觉得，还是在保证效果的前提下，网络越简单越好，这样能保证请求延迟等各方面都处在比较好的程度。如果为了提高0.1%的效果，消耗了远远多与收益的成本，对于企业来说是不划算的。比如，xdeepfm，nffm，完全是堆积木。\n",
    "\n",
    "4. Deep 侧的泛化能力是什么？  \n",
    "Deep 的泛化能力指的是对于历史数据中未出现的或者很少的特征组合也能给出正确的预测，即使**出现了新的特征组合也能够正确推断出其对目标变量的贡献**。为什么 Deep 部分能泛化呢？Deep 侧对类别特征进行了表征，利用历史数据发掘特征之间隐藏的关系。deep部分的作用就是泛化，为的就是解决预测数据中出现wide部分没有包含的特征，尤其是ID组合特征。\n",
    "\n",
    "5. 为什么Wide部分要用L1 FTRL训练？  \n",
    "几年前FTRL曾风靡全部互联网头部公司，成为线性模型在线训练的主要方法。\n",
    "简要来说，可以把FTRL当作一个**稀疏性**很好，精度又不错的随机梯度下降方法。由于是随机梯度下降，当然可以做到来一个样本就训练一次，进而实现模型的在线更新。所以在四五年前，大部分公司还是线性模型为主的时代，FTRL 凭借非常好的在线学习能力成为主流。问在这里“稀疏”这个性质又冒出来了。也就是说FTRL with L1非常注重模型的稀疏性。这也就是问题的答案，W&D 采用 L1 FTRL 是想让 Wide 部分变得更加稀疏。\n",
    "再白话一点就是，L1 FTRL 会让 Wide 部分的大部分权重都为 0，我们**准备特征的时候就不用准备那么多0权重的特征了**，这大大压缩了模型权重，也压缩了特征向量的维度。\n",
    "\n",
    "6. 为什么Deep部分不特别考虑稀疏性的问题？  \n",
    "大家注意观察可以发现Deep部分的输入，要么是Age，#App Installs这些数值类特征，要么是已经降维并稠密化的Embedding向量，工程师们不会也不敢把过度稀疏的特征向量直接输入到Deep网络中。所以Deep部分不存在严重的特征稀疏问题，自然可以使用精度更好，更适用于深度学习训练的AdaGrad去训练。\n",
    "\n",
    "7. 为什么L1正则化比L2正则化更容易产生稀疏解？\n",
    "![从优化视角](./imgs/l1-l2_1.jpg)\n",
    "![从梯度视角](./imgs/l1-l2_2.jpg)\n",
    "![从概率视角](./imgs/l1-l2_3.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda4bbfd-2c14-4e9e-a96d-f6d0532444b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
